{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c5b049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./mbert_trained_mix_2.0/ were not used when initializing BertForPreTraining: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing BertForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at ./mbert_trained_mix_2.0/ and are newly initialized: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_logits: tensor([[[-0.7960, -0.4499, -0.2590,  ..., -1.3657, -0.6401,  0.1440],\n",
      "         [ 0.4767,  0.4180,  0.0518,  ...,  0.7086, -0.2624, -0.3882],\n",
      "         [ 0.2944,  0.1217, -0.0426,  ..., -0.0133,  0.0677, -0.4058],\n",
      "         ...,\n",
      "         [ 0.3072,  0.4365, -0.0385,  ...,  0.3094, -0.3532, -0.4403],\n",
      "         [ 0.0200, -0.2791, -0.5170,  ..., -0.4483, -0.6695, -1.1791],\n",
      "         [-0.3772, -0.9417, -0.7060,  ..., -1.8003, -0.2143, -1.7891]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "seq_relationship_logits: tensor([[ 0.1569, -0.0778]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForPreTraining\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./mbert_trained_mix_2.0/\")\n",
    "model = BertForPreTraining.from_pretrained(\"./mbert_trained_mix_2.0/\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "prediction_logits = outputs.prediction_logits\n",
    "seq_relationship_logits = outputs.seq_relationship_logits\n",
    "\n",
    "print(f'prediction_logits: {prediction_logits}')\n",
    "print(f'seq_relationship_logits: {seq_relationship_logits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd94e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qiita.com/m__k/items/e312ddcf9a3d0ea64d72\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "\n",
    "# https://huggingface.co/docs/transformers/main_classes/model#transformers.PreTrainedModel.from_pretrained\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    './mbert_trained_mix_2.0/'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    './mbert_trained_mix_2.0/'\n",
    ")\n",
    "config = AutoConfig.from_pretrained(\n",
    "    './mbert_trained_mix_2.0/'\n",
    ")\n",
    "\n",
    "# from transformers.trainer_utils import get_last_checkpoint\n",
    "# last_checkpoint = get_last_checkpoint('./') # training_args.output_dir\n",
    "\n",
    "# input the test_file\n",
    "# Field object and TabularDataset object\n",
    "\n",
    "from torchtext import data\n",
    "\n",
    "TEXT = data.Field(tokenize=tokenizer)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "test_data = torchtext.data.TabularDataset.splits(\n",
    "    path = './dataset/test_knowhow/',\n",
    "    test = 'test_v2.4_job_neo.json',\n",
    "    format = 'json',\n",
    "    fields=[('Text', TEXT), ('label',LABEL)]\n",
    ")\n",
    "\n",
    "# BERTの順伝搬ときにoutput_attention = Trueで、Attention weightを取得できる\n",
    "batch = next(iter(test_iter))\n",
    "\n",
    "last_hidden_state, pooler_output, attentions = model(batch.Text[0], output_attentions=True)\n",
    "print(last_hidden_state.size())\n",
    "print(pooler_output_size())\n",
    "print(len(attentions), attentions[-1].size())\n",
    "\n",
    "# GPUの設定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# prediction\n",
    "from utils_qa import postprocess_qa_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6f3e18b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-13ffdd2859327b95\n",
      "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-13ffdd2859327b95/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022e9b193fdb454db59921b8226bc595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "志望 動機 を 答える 際 の ポイント は ？ \n",
      "志望 動機 を 答える 際 の ポイント は 、 なぜ その 企業 で なけれ ば なら ない か を 徹底的 に 突き詰める こと 。 この 企業 で なけれ ば なら ない という 熱意 が 強く 伝われ ば 伝わる ほど 、 面接 官 の 印象 は アップ し ます 。 志望 動機 の 考え方 と 実際 の 作り方 は 、 下記 記事 を 参考 に し て ください 。 \n",
      "torch.Size([1, 125])\n",
      "なせ その 企 業 て なけれ は なら ない か を 徹 底 的 に 突 き 詰 める こと\n",
      "torch.Size([1, 12, 125, 125])\n"
     ]
    }
   ],
   "source": [
    "import run_qa\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "# https://huggingface.co/docs/transformers/main_classes/model#transformers.PreTrainedModel.from_pretrained\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    './mbert_trained_mix_2.0/'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    './mbert_trained_mix_2.0/'\n",
    ")\n",
    "config = AutoConfig.from_pretrained(\n",
    "    './mbert_trained_mix_2.0/'\n",
    ")\n",
    "\n",
    "# GPUの設定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "## 如何输入数据集？？？\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "raw_datasets = load_dataset(\n",
    "    'json',\n",
    "    data_files={'test':'./dataset/test_knowhow/test_v2.4_job_neo.json'},\n",
    "    field='data',\n",
    "    # data_args.dataset_config_name,\n",
    "    # cache_dir=model_args.cache_dir,\n",
    "    use_auth_token=True\n",
    ")\n",
    "column_names = raw_datasets['test'].column_names\n",
    "question_column_name = \"question\"\n",
    "context_column_name = \"context\"\n",
    "answer_column_name = \"answer\"\n",
    "\n",
    "#print(raw_datasets['test'][question_column_name])\n",
    "\n",
    "# print(f'column_names:{column_names}')\n",
    "# print(f'question_column_name:{question_column_name}')\n",
    "# print(f'context_column_name:{context_column_name}')\n",
    "# print(f'answer_column_name:{answer_column_name}')\n",
    "\n",
    "# 从config中读取model的情报\n",
    "\n",
    "question = raw_datasets['test'][question_column_name][1]\n",
    "context = raw_datasets['test'][context_column_name][1]\n",
    "\n",
    "print(question)\n",
    "print(context)\n",
    "\n",
    "inputs = tokenizer(\n",
    "    question, \n",
    "    context,\n",
    "    max_length=384,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "print(inputs.input_ids.size()) # [batch_size, sequence_length]\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_attentions=True)\n",
    "\n",
    "#print(outputs)\n",
    "\n",
    "answer_start_index = outputs.start_logits.argmax()\n",
    "answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index:answer_end_index+1]\n",
    "answer_predicted = tokenizer.decode(predict_answer_tokens)\n",
    "print(answer_predicted)\n",
    "\n",
    "# attention\n",
    "attentions = outputs.attentions\n",
    "attention_weights = attentions[-1]\n",
    "# 最後の層のattentionを取得したい\n",
    "print(attention_weights.size())\n",
    "# [batch_size, num_heads. sequence_length, sequence_length]\n",
    "# print(f'attentions: {attention_weight}')\n",
    "    \n",
    "# from run_qa import prepare_validation_features\n",
    "\n",
    "# predict_dataset = predict_examples.map(\n",
    "#    prepare_validation_features,\n",
    "#    batched=True,\n",
    "#    # num_proc=data_args.preprocessing_num_workers,\n",
    "#    remove_columns=column_names,\n",
    "#    # load_from_cache_file=not data_args.overwrite_cache,\n",
    "#    desc=\"Running tokenizer on prediction dataset\",\n",
    "#)\n",
    "\n",
    "\n",
    "# prediction\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"*** Predict ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3a5042c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "予測回答: なせ その 企 業 て なけれ は なら ない か を 徹 底 的 に 突 き 詰 める こと<br><span style=\"background-color: #FFBDBD\">[CLS]</span><span style=\"background-color: #FFD9D9\">志</span><span style=\"background-color: #FFE8E8\">望</span><span style=\"background-color: #FFE4E4\">動</span><span style=\"background-color: #FFE4E4\">機</span><span style=\"background-color: #FFEAEA\">を</span><span style=\"background-color: #FFE7E7\">答</span><span style=\"background-color: #FFDADA\">える</span><span style=\"background-color: #FFEAEA\">際</span><span style=\"background-color: #FFDADA\">の</span><span style=\"background-color: #FFE9E9\">ホ</span><span style=\"background-color: #FFE3E3\">##イント</span><span style=\"background-color: #FFD8D8\">は</span><span style=\"background-color: #FFABAB\">？</span><span style=\"background-color: #FF-5F-5F\">[SEP]</span><span style=\"background-color: #FFE6E6\">志</span><span style=\"background-color: #FFD1D1\">望</span><span style=\"background-color: #FFDDDD\">動</span><span style=\"background-color: #FFA5A5\">機</span><span style=\"background-color: #FFCACA\">を</span><span style=\"background-color: #FFB9B9\">答</span><span style=\"background-color: #FF9D9D\">える</span><span style=\"background-color: #FF8A8A\">際</span><span style=\"background-color: #FFDADA\">の</span><span style=\"background-color: #FFD9D9\">ホ</span><span style=\"background-color: #FF8E8E\">##イント</span><span style=\"background-color: #FFD7D7\">は</span><span style=\"background-color: #FFF2F2\">、</span><span style=\"background-color: #FFF7F7\">な</span><span style=\"background-color: #FFBBBB\">##せ</span><span style=\"background-color: #FFF2F2\">その</span><span style=\"background-color: #FFD5D5\">企</span><span style=\"background-color: #FFE8E8\">業</span><span style=\"background-color: #FFFCFC\">て</span><span style=\"background-color: #FFFCFC\">な</span><span style=\"background-color: #FFF8F8\">##け</span><span style=\"background-color: #FFFAFA\">##れ</span><span style=\"background-color: #FFFDFD\">は</span><span style=\"background-color: #FFFDFD\">な</span><span style=\"background-color: #FFF7F7\">##ら</span><span style=\"background-color: #FFF6F6\">ない</span><span style=\"background-color: #FFFDFD\">か</span><span style=\"background-color: #FFFBFB\">を</span><span style=\"background-color: #FFF6F6\">徹</span><span style=\"background-color: #FFCDCD\">底</span><span style=\"background-color: #FFCCCC\">的</span><span style=\"background-color: #FFFDFD\">に</span><span style=\"background-color: #FFFBFB\">突</span><span style=\"background-color: #FFFAFA\">き</span><span style=\"background-color: #FFF8F8\">詰</span><span style=\"background-color: #FFE3E3\">める</span><span style=\"background-color: #FFF0F0\">こ</span><span style=\"background-color: #FFE8E8\">##と</span><span style=\"background-color: #FFE3E3\">。</span><span style=\"background-color: #FFFDFD\">この</span><span style=\"background-color: #FFF1F1\">企</span><span style=\"background-color: #FFF8F8\">業</span><span style=\"background-color: #FFFDFD\">て</span><span style=\"background-color: #FFFDFD\">な</span><span style=\"background-color: #FFFCFC\">##け</span><span style=\"background-color: #FFFDFD\">##れ</span><span style=\"background-color: #FFFDFD\">は</span><span style=\"background-color: #FFFDFD\">な</span><span style=\"background-color: #FFF9F9\">##ら</span><span style=\"background-color: #FFFDFD\">ない</span><span style=\"background-color: #FFFEFE\">という</span><span style=\"background-color: #FFFEFE\">熱</span><span style=\"background-color: #FFFEFE\">意</span><span style=\"background-color: #FFFEFE\">か</span><span style=\"background-color: #FFFEFE\">強</span><span style=\"background-color: #FFFEFE\">く</span><span style=\"background-color: #FFFEFE\">伝</span><span style=\"background-color: #FFFEFE\">われ</span><span style=\"background-color: #FFFDFD\">は</span><span style=\"background-color: #FFFEFE\">伝</span><span style=\"background-color: #FFFEFE\">わる</span><span style=\"background-color: #FFFDFD\">ほ</span><span style=\"background-color: #FFFCFC\">##と</span><span style=\"background-color: #FFFCFC\">、</span><span style=\"background-color: #FFFEFE\">面</span><span style=\"background-color: #FFFCFC\">接</span><span style=\"background-color: #FFFBFB\">官</span><span style=\"background-color: #FFFEFE\">の</span><span style=\"background-color: #FFFEFE\">印</span><span style=\"background-color: #FFFEFE\">象</span><span style=\"background-color: #FFFEFE\">は</span><span style=\"background-color: #FFFEFE\">ア</span><span style=\"background-color: #FFFEFE\">##ッフ</span><span style=\"background-color: #FFFEFE\">し</span><span style=\"background-color: #FFFEFE\">ま</span><span style=\"background-color: #FFFCFC\">##す</span><span style=\"background-color: #FF-50-50\">。</span><span style=\"background-color: #FFFEFE\">志</span><span style=\"background-color: #FFFDFD\">望</span><span style=\"background-color: #FFFEFE\">動</span><span style=\"background-color: #FFFEFE\">機</span><span style=\"background-color: #FFFEFE\">の</span><span style=\"background-color: #FFFEFE\">考</span><span style=\"background-color: #FFFDFD\">え</span><span style=\"background-color: #FFFEFE\">方</span><span style=\"background-color: #FFFEFE\">と</span><span style=\"background-color: #FFFEFE\">実</span><span style=\"background-color: #FFFEFE\">際</span><span style=\"background-color: #FFFEFE\">の</span><span style=\"background-color: #FFFEFE\">作</span><span style=\"background-color: #FFFDFD\">り</span><span style=\"background-color: #FFFDFD\">方</span><span style=\"background-color: #FFFEFE\">は</span><span style=\"background-color: #FFFDFD\">、</span><span style=\"background-color: #FFFEFE\">下</span><span style=\"background-color: #FFFEFE\">記</span><span style=\"background-color: #FFFDFD\">記</span><span style=\"background-color: #FFFEFE\">事</span><span style=\"background-color: #FFFEFE\">を</span><span style=\"background-color: #FFFEFE\">参</span><span style=\"background-color: #FFFEFE\">考</span><span style=\"background-color: #FFFEFE\">に</span><span style=\"background-color: #FFFEFE\">し</span><span style=\"background-color: #FFFEFE\">て</span><span style=\"background-color: #FFFEFE\">く</span><span style=\"background-color: #FFFEFE\">##た</span><span style=\"background-color: #FFFEFE\">##さ</span><span style=\"background-color: #FFFEFE\">##い</span><span style=\"background-color: #FF-13-13\">。</span><span style=\"background-color: #FF-60-60\">[SEP]</span><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the part of attention visualization\n",
    "def highlight(word, attn):\n",
    "    html_color = '#%02X%02X%02X' % (255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return '<span style=\"background-color: {}\">{}</span>'.format(html_color, word)\n",
    "\n",
    "def mk_html(index, inputs, preds, attention_weight):  \n",
    "    sentence = inputs[index]\n",
    "    #pred\n",
    "    \n",
    "    # label_str = \"label_str\"\n",
    "    pred_str = preds\n",
    "    \n",
    "    html = \"予測回答: {}<br>\".format(pred_str)\n",
    "    \n",
    "    # 文章の長さ分のzero tensorを宣言\n",
    "    seq_len = inputs.size()[1] # sequence_length\n",
    "    device_cpu = torch.device(\"cpu\")\n",
    "    all_attens = torch.zeros(seq_len).to(device_cpu)\n",
    "    \n",
    "    for i in range(12):\n",
    "        all_attens += attention_weight[index, i, 0, :]\n",
    "        \n",
    "    for word, attn in zip(sentence, all_attens):\n",
    "        #if tokenizer.convert_ids_to_tokens([word.tolist()])[0] == \"[SEP]\":\n",
    "        #    break\n",
    "        html += highlight(tokenizer.convert_ids_to_tokens([word.numpy().tolist()])[0], attn)\n",
    "    html += \"<br><br>\"\n",
    "    return html\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "html_output = mk_html(\n",
    "    0,\n",
    "    inputs.input_ids,\n",
    "    answer_predicted,\n",
    "    attentions[-1]\n",
    ")\n",
    "display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec037ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
